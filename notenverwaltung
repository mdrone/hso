#!/usr/bin/python2.7

import sys
import mechanize
import re
import cookielib
from bs4 import BeautifulSoup

def average (url, browser):
    temp = browser
    response = temp.open(url)
    soup = BeautifulSoup(response)
    table = soup.table.extract()
    table = soup.table.extract()
    table = soup.table.extract()

    for rows in table.findAll('tr'):
        average_grade = ""
        for columns in rows.findAll('td'):
            average_grade += columns.getText()
    average_grade = re.sub("^\s+\w+\s", "", average_grade)
    if len(average_grade) < 4:
        return average_grade
    else :
        return "N/A"

def print_line (line):
    #line = line.split(" :: ")
    #print "{0:<10} {0:<10}".format(line)
    print line

if len(sys.argv) < 2:
    sys.exit('Usage: %s [username] [password]' % sys.argv[0])
else :
    username = sys.argv[1]
    password = sys.argv[2]

start_url           = "https://notenverwaltung.hs-offenburg.de/qispos/rds?state=user&type=0";
form                = "loginform";
form_field_user     = "asdf";
form_field_password = "fdsa";
noten_uebersicht    = "Noten";
noten_info          = "Leistungen";
logout              = "Abmelden";

cookiejar           = cookielib.LWPCookieJar()

browser             = mechanize.Browser()

browser.set_cookiejar(cookiejar)
browser.set_handle_redirect(True)
browser.set_handle_referer(True)
browser.open(start_url)

browser.select_form(form)
browser.form[form_field_user]       = username
browser.form[form_field_password]   = password

response                            = browser.submit()

url                                 = browser.find_link(text_regex = re.compile(noten_uebersicht))
response                            = browser.follow_link(url)

url                                 = browser.find_link(text_regex = re.compile(noten_info))
response                            = browser.follow_link(url)

soup                                = BeautifulSoup(response)
table                               = soup.table.extract()
table                               = soup.table.extract()

for rows in table.findAll('tr'):
    line = ""
    for columns in rows.findAll('td'):
        line += columns.getText()
        for link in columns.findAll('a'):
            url = link.get('href')
            line += "(Schnitt: " + average(url, browser) + ")"
    line = re.sub("\n", "", line)
    line = re.sub("^\s+", "", line)
    line = re.sub("\s+$", "", line)
    line = re.sub("\s\s+", " :: ", line)
    line = re.sub("\s\s+", " :: ", line)
    line = re.sub(" :: \d :: \d{2}.\d{2}\.\d{4}$", "", line)
    line = re.sub(" :: \d$", "", line)
    #if re.search("^UIS-\d\d\d\s", line):
        #print ""
    if re.search("Zwischen", line):
        print_line(line)
    if re.search("Studienabschnitt", line):
        print
        #print split_line(line)
        print_line(line)
        print
    if not re.match("^UIS-\d\d\s", line) and not re.match("^UIS-\d\d\d\s", line):
        print_line(line)
        #print line.split("::")
    #if re.search("^UIS-\d\d\d\s", line):
        #print ""

url                                 = browser.find_link(text_regex = re.compile(logout))
response                            = browser.follow_link(url)
